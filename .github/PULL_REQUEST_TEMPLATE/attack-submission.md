## Attack Information

- **Paper Title**:
- **Paper URL**:
- **Paper authors**:

## Benchmark Claim

Add here the claim for your attack.

- [ ] I am including a file containing the json output by `evaluate_prompts` for the `vicuna` and `llama-2` models in the [`/jailbreak_artifacts/](/jailbreak_artifacts) directory. You can look at [this example](/jailbreak_artifacts/GCG/) for the directory and files format.
- [ ] I authorize adding my jailbreak strings to the benchmark
- [ ] I agree to release my jailbreak strings under MIT license (check if true) **OR** under a custom license, located here: (put the custom license URL here if a custom license is needed. If no URL is specified, we assume that you are fine with MIT)


## Jailbreak strings artifact:

TODO: tick the following boxes if you want to add your jailbreak strings to the benchmark

- [ ] I am including a file with the jailbreak strings for the `vicuna` and `llama-2` models in `/jailbreak_artifacts/<attack_name>`. 
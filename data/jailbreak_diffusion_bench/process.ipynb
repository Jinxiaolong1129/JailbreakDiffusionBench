{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总prompts数量: 15750\n",
      "\n",
      "不同的source来源:\n",
      "  DIffusion-DB: 10806条\n",
      "  I2P: 1335条\n",
      "  web: 1074条\n",
      "  MMA_adv_prompt: 1000条\n",
      "  MMA_sanitized_adv_prompt: 1000条\n",
      "  sneaky: 183条\n",
      "  Civitai-8m-prompts: 140条\n",
      "  4chan: 122条\n",
      "  VBCDE: 90条\n",
      "总source数量: 9\n",
      "\n",
      "不同的category分类:\n",
      "  safe: 10000条\n",
      "  jailbreak: 1000条\n",
      "  sanitized-jailbreak: 1000条\n",
      "  shocking: 596条\n",
      "  nudity and sexual content: 521条\n",
      "  hate content: 513条\n",
      "  discrimination and disinformation: 505条\n",
      "  illegal activity: 482条\n",
      "  physical harm and violence: 382条\n",
      "  copyright infringement: 313条\n",
      "  harassment: 231条\n",
      "  abuse: 213条\n",
      "总category数量: 12\n",
      "\n",
      "每个source的category分布:\n",
      "  4chan:\n",
      "    - hate content: 84条\n",
      "    - nudity and sexual content: 27条\n",
      "    - discrimination and disinformation: 5条\n",
      "    - illegal activity: 3条\n",
      "    - shocking: 3条\n",
      "    - harassment: 1条\n",
      "  Civitai-8m-prompts:\n",
      "    - nudity and sexual content: 99条\n",
      "    - shocking: 41条\n",
      "  DIffusion-DB:\n",
      "    - safe: 10000条\n",
      "    - discrimination and disinformation: 251条\n",
      "    - hate content: 200条\n",
      "    - shocking: 182条\n",
      "    - copyright infringement: 85条\n",
      "    - nudity and sexual content: 59条\n",
      "    - illegal activity: 19条\n",
      "    - physical harm and violence: 15条\n",
      "  I2P:\n",
      "    - shocking: 370条\n",
      "    - discrimination and disinformation: 249条\n",
      "    - copyright infringement: 228条\n",
      "    - illegal activity: 207条\n",
      "    - nudity and sexual content: 121条\n",
      "    - physical harm and violence: 114条\n",
      "    - hate content: 37条\n",
      "    - harassment: 6条\n",
      "    - abuse: 3条\n",
      "  MMA_adv_prompt:\n",
      "    - jailbreak: 1000条\n",
      "  MMA_sanitized_adv_prompt:\n",
      "    - sanitized-jailbreak: 1000条\n",
      "  VBCDE:\n",
      "    - hate content: 33条\n",
      "    - nudity and sexual content: 32条\n",
      "    - illegal activity: 25条\n",
      "  sneaky:\n",
      "    - nudity and sexual content: 183条\n",
      "  web:\n",
      "    - physical harm and violence: 253条\n",
      "    - illegal activity: 228条\n",
      "    - harassment: 224条\n",
      "    - abuse: 210条\n",
      "    - hate content: 159条\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_json(file_path):\n",
    "    \"\"\"\n",
    "    分析JSON文件中的source和category数据\n",
    "    \n",
    "    参数:\n",
    "    file_path: JSON文件的路径\n",
    "    \n",
    "    返回:\n",
    "    分析结果的字典\n",
    "    \"\"\"\n",
    "    # 读取JSON文件\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 初始化计数器\n",
    "    sources = collections.Counter()\n",
    "    categories = collections.Counter()\n",
    "    source_category_count = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "    \n",
    "    # 分析每个prompt\n",
    "    for prompt in data.get('prompts', []):\n",
    "        source = prompt.get('source', 'unknown')\n",
    "        cats = prompt.get('category', [])\n",
    "        \n",
    "        # 增加source计数\n",
    "        sources[source] += 1\n",
    "        \n",
    "        # 处理category (每个prompt的category是一个列表)\n",
    "        for cat in cats:\n",
    "            categories[cat] += 1\n",
    "            source_category_count[source][cat] += 1\n",
    "    \n",
    "    # 计算结果\n",
    "    result = {\n",
    "        'total_prompts': len(data.get('prompts', [])),\n",
    "        'sources': dict(sources),\n",
    "        'source_count': len(sources),\n",
    "        'categories': dict(categories),\n",
    "        'category_count': len(categories),\n",
    "        'source_category_breakdown': {s: dict(c) for s, c in source_category_count.items()}\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # 文件路径\n",
    "    file_path = 'text_checker_eval.json'\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    if not Path(file_path).exists():\n",
    "        print(f\"错误: 找不到文件 '{file_path}'\")\n",
    "        return\n",
    "    \n",
    "    # 分析数据\n",
    "    try:\n",
    "        result = analyze_json(file_path)\n",
    "        \n",
    "        # 打印结果\n",
    "        print(f\"总prompts数量: {result['total_prompts']}\")\n",
    "        print(\"\\n不同的source来源:\")\n",
    "        for source, count in sorted(result['sources'].items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {source}: {count}条\")\n",
    "        print(f\"总source数量: {result['source_count']}\")\n",
    "        \n",
    "        print(\"\\n不同的category分类:\")\n",
    "        for category, count in sorted(result['categories'].items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {category}: {count}条\")\n",
    "        print(f\"总category数量: {result['category_count']}\")\n",
    "        \n",
    "        print(\"\\n每个source的category分布:\")\n",
    "        for source, cats in sorted(result['source_category_breakdown'].items()):\n",
    "            print(f\"  {source}:\")\n",
    "            for cat, count in sorted(cats.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"    - {cat}: {count}条\")\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"错误: JSON格式无效\")\n",
    "    except Exception as e:\n",
    "        print(f\"分析过程中出错: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已创建总体统计CSV: json_analysis_summary.csv\n",
      "已创建交叉分析CSV: json_analysis_cross.csv\n",
      "已创建长格式CSV: json_analysis_long.csv\n",
      "所有CSV文件已生成完成。\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# 创建总体统计表格\n",
    "def create_summary_csv():\n",
    "    with open('json_analysis_summary.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # 写入总数据\n",
    "        writer.writerow(['总统计'])\n",
    "        writer.writerow(['总prompts数量', '15750'])\n",
    "        writer.writerow(['总source数量', '9'])\n",
    "        writer.writerow(['总category数量', '12'])\n",
    "        writer.writerow([])\n",
    "        \n",
    "        # 写入source统计\n",
    "        writer.writerow(['Source统计'])\n",
    "        writer.writerow(['Source', '数量'])\n",
    "        sources = [\n",
    "            ('DIffusion-DB', 10806),\n",
    "            ('I2P', 1335),\n",
    "            ('web', 1074),\n",
    "            ('MMA_adv_prompt', 1000),\n",
    "            ('MMA_sanitized_adv_prompt', 1000),\n",
    "            ('sneaky', 183),\n",
    "            ('Civitai-8m-prompts', 140),\n",
    "            ('4chan', 122),\n",
    "            ('VBCDE', 90)\n",
    "        ]\n",
    "        for source, count in sources:\n",
    "            writer.writerow([source, count])\n",
    "        writer.writerow([])\n",
    "        \n",
    "        # 写入category统计\n",
    "        writer.writerow(['Category统计'])\n",
    "        writer.writerow(['Category', '数量'])\n",
    "        categories = [\n",
    "            ('safe', 10000),\n",
    "            ('jailbreak', 1000),\n",
    "            ('sanitized-jailbreak', 1000),\n",
    "            ('shocking', 596),\n",
    "            ('nudity and sexual content', 521),\n",
    "            ('hate content', 513),\n",
    "            ('discrimination and disinformation', 505),\n",
    "            ('illegal activity', 482),\n",
    "            ('physical harm and violence', 382),\n",
    "            ('copyright infringement', 313),\n",
    "            ('harassment', 231),\n",
    "            ('abuse', 213)\n",
    "        ]\n",
    "        for category, count in categories:\n",
    "            writer.writerow([category, count])\n",
    "    \n",
    "    print(f\"已创建总体统计CSV: json_analysis_summary.csv\")\n",
    "\n",
    "# 创建source和category的交叉分析表格\n",
    "def create_cross_analysis_csv():\n",
    "    # 所有source和category列表\n",
    "    sources = [\n",
    "        'DIffusion-DB', 'I2P', 'web', 'MMA_adv_prompt', \n",
    "        'MMA_sanitized_adv_prompt', 'sneaky', 'Civitai-8m-prompts', \n",
    "        '4chan', 'VBCDE'\n",
    "    ]\n",
    "    \n",
    "    categories = [\n",
    "        'safe', 'jailbreak', 'sanitized-jailbreak', 'shocking',\n",
    "        'nudity and sexual content', 'hate content', 'discrimination and disinformation',\n",
    "        'illegal activity', 'physical harm and violence', 'copyright infringement',\n",
    "        'harassment', 'abuse'\n",
    "    ]\n",
    "    \n",
    "    # 数据字典\n",
    "    data = {\n",
    "        '4chan': {\n",
    "            'hate content': 84,\n",
    "            'nudity and sexual content': 27,\n",
    "            'discrimination and disinformation': 5,\n",
    "            'illegal activity': 3,\n",
    "            'shocking': 3,\n",
    "            'harassment': 1\n",
    "        },\n",
    "        'Civitai-8m-prompts': {\n",
    "            'nudity and sexual content': 99,\n",
    "            'shocking': 41\n",
    "        },\n",
    "        'DIffusion-DB': {\n",
    "            'safe': 10000,\n",
    "            'discrimination and disinformation': 251,\n",
    "            'hate content': 200,\n",
    "            'shocking': 182,\n",
    "            'copyright infringement': 85,\n",
    "            'nudity and sexual content': 59,\n",
    "            'illegal activity': 19,\n",
    "            'physical harm and violence': 15\n",
    "        },\n",
    "        'I2P': {\n",
    "            'shocking': 370,\n",
    "            'discrimination and disinformation': 249,\n",
    "            'copyright infringement': 228,\n",
    "            'illegal activity': 207,\n",
    "            'nudity and sexual content': 121,\n",
    "            'physical harm and violence': 114,\n",
    "            'hate content': 37,\n",
    "            'harassment': 6,\n",
    "            'abuse': 3\n",
    "        },\n",
    "        'MMA_adv_prompt': {\n",
    "            'jailbreak': 1000\n",
    "        },\n",
    "        'MMA_sanitized_adv_prompt': {\n",
    "            'sanitized-jailbreak': 1000\n",
    "        },\n",
    "        'VBCDE': {\n",
    "            'hate content': 33,\n",
    "            'nudity and sexual content': 32,\n",
    "            'illegal activity': 25\n",
    "        },\n",
    "        'sneaky': {\n",
    "            'nudity and sexual content': 183\n",
    "        },\n",
    "        'web': {\n",
    "            'physical harm and violence': 253,\n",
    "            'illegal activity': 228,\n",
    "            'harassment': 224,\n",
    "            'abuse': 210,\n",
    "            'hate content': 159\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 创建交叉表格\n",
    "    with open('json_analysis_cross.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # 写入表头\n",
    "        header = ['Source'] + categories\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # 写入数据行\n",
    "        for source in sources:\n",
    "            row = [source]\n",
    "            for category in categories:\n",
    "                count = data.get(source, {}).get(category, 0)\n",
    "                row.append(count)\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(f\"已创建交叉分析CSV: json_analysis_cross.csv\")\n",
    "\n",
    "# 创建另一种格式的表格：长格式，每行一个(source, category, count)\n",
    "def create_long_format_csv():\n",
    "    with open('json_analysis_long.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # 写入表头\n",
    "        writer.writerow(['Source', 'Category', 'Count'])\n",
    "        \n",
    "        # 数据\n",
    "        data = [\n",
    "            ('4chan', 'hate content', 84),\n",
    "            ('4chan', 'nudity and sexual content', 27),\n",
    "            ('4chan', 'discrimination and disinformation', 5),\n",
    "            ('4chan', 'illegal activity', 3),\n",
    "            ('4chan', 'shocking', 3),\n",
    "            ('4chan', 'harassment', 1),\n",
    "            ('Civitai-8m-prompts', 'nudity and sexual content', 99),\n",
    "            ('Civitai-8m-prompts', 'shocking', 41),\n",
    "            ('DIffusion-DB', 'safe', 10000),\n",
    "            ('DIffusion-DB', 'discrimination and disinformation', 251),\n",
    "            ('DIffusion-DB', 'hate content', 200),\n",
    "            ('DIffusion-DB', 'shocking', 182),\n",
    "            ('DIffusion-DB', 'copyright infringement', 85),\n",
    "            ('DIffusion-DB', 'nudity and sexual content', 59),\n",
    "            ('DIffusion-DB', 'illegal activity', 19),\n",
    "            ('DIffusion-DB', 'physical harm and violence', 15),\n",
    "            ('I2P', 'shocking', 370),\n",
    "            ('I2P', 'discrimination and disinformation', 249),\n",
    "            ('I2P', 'copyright infringement', 228),\n",
    "            ('I2P', 'illegal activity', 207),\n",
    "            ('I2P', 'nudity and sexual content', 121),\n",
    "            ('I2P', 'physical harm and violence', 114),\n",
    "            ('I2P', 'hate content', 37),\n",
    "            ('I2P', 'harassment', 6),\n",
    "            ('I2P', 'abuse', 3),\n",
    "            ('MMA_adv_prompt', 'jailbreak', 1000),\n",
    "            ('MMA_sanitized_adv_prompt', 'sanitized-jailbreak', 1000),\n",
    "            ('VBCDE', 'hate content', 33),\n",
    "            ('VBCDE', 'nudity and sexual content', 32),\n",
    "            ('VBCDE', 'illegal activity', 25),\n",
    "            ('sneaky', 'nudity and sexual content', 183),\n",
    "            ('web', 'physical harm and violence', 253),\n",
    "            ('web', 'illegal activity', 228),\n",
    "            ('web', 'harassment', 224),\n",
    "            ('web', 'abuse', 210),\n",
    "            ('web', 'hate content', 159)\n",
    "        ]\n",
    "        \n",
    "        # 写入数据\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(f\"已创建长格式CSV: json_analysis_long.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建所有CSV文件\n",
    "    create_summary_csv()\n",
    "    create_cross_analysis_csv()\n",
    "    create_long_format_csv()\n",
    "    \n",
    "    print(\"所有CSV文件已生成完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重排ID完成，已保存到 jailbreak_diffusion_bench.json\n",
      "总记录数: 15750\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def reindex_json(input_path, output_path):\n",
    "    \"\"\"\n",
    "    读取JSON文件，对prompts中的id进行重排，从1开始递增，然后保存为新的JSON文件\n",
    "    \n",
    "    参数:\n",
    "    input_path: 输入JSON文件的路径\n",
    "    output_path: 输出JSON文件的路径\n",
    "    \"\"\"\n",
    "    # 读取JSON文件\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 重新编号\n",
    "    for i, prompt in enumerate(data.get('prompts', []), 1):\n",
    "        prompt['id'] = i\n",
    "    \n",
    "    # 保存为新文件\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"重排ID完成，已保存到 {output_path}\")\n",
    "    print(f\"总记录数: {len(data.get('prompts', []))}\")\n",
    "\n",
    "def main():\n",
    "    # 文件路径\n",
    "    input_path = 'text_checker_eval.json'\n",
    "    output_path = 'jailbreak_diffusion_bench.json'\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    if not Path(input_path).exists():\n",
    "        print(f\"错误: 找不到文件 '{input_path}'\")\n",
    "        return\n",
    "    \n",
    "    # 执行重排\n",
    "    try:\n",
    "        reindex_json(input_path, output_path)\n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出错: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽取完成，已保存到 jailbreak_diffusion_bench_filtered.json\n",
      "总抽取记录数: 400\n",
      "\n",
      "各来源和类别的抽取统计:\n",
      "  Civitai-8m-prompts:\n",
      "    - nudity and sexual content: 25条\n",
      "    - shocking: 25条\n",
      "  DIffusion-DB:\n",
      "    - discrimination and disinformation: 25条\n",
      "    - hate content: 25条\n",
      "    - illegal activity: 19条\n",
      "    - physical harm and violence: 15条\n",
      "  I2P:\n",
      "    - abuse: 3条\n",
      "    - discrimination and disinformation: 25条\n",
      "    - harassment: 6条\n",
      "    - hate content: 10条\n",
      "    - illegal activity: 11条\n",
      "    - physical harm and violence: 15条\n",
      "    - shocking: 25条\n",
      "  sneaky:\n",
      "    - nudity and sexual content: 25条\n",
      "  web:\n",
      "    - abuse: 47条\n",
      "    - harassment: 44条\n",
      "    - hate content: 15条\n",
      "    - illegal activity: 20条\n",
      "    - physical harm and violence: 20条\n",
      "\n",
      "各类别总计:\n",
      "  abuse: 50条\n",
      "  discrimination and disinformation: 50条\n",
      "  harassment: 50条\n",
      "  hate content: 50条\n",
      "  illegal activity: 50条\n",
      "  nudity and sexual content: 50条\n",
      "  physical harm and violence: 50条\n",
      "  shocking: 50条\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import collections\n",
    "\n",
    "def extract_prompts(input_path, output_path):\n",
    "    \"\"\"\n",
    "    按照给定的表格需求，从每个类别抽取指定数量的提示\n",
    "    \n",
    "    参数:\n",
    "    input_path: 输入JSON文件的路径\n",
    "    output_path: 输出JSON文件的路径\n",
    "    \"\"\"\n",
    "    # 表格要求 - 修正后与表格完全一致\n",
    "    requirements = {\n",
    "        'DIffusion-DB': {\n",
    "            'shocking': 0, \n",
    "            'nudity and sexual content': 0, \n",
    "            'hate content': 25, \n",
    "            'discrimination and disinformation': 25, \n",
    "            'illegal activity': 19, \n",
    "            'physical harm and violence': 15, \n",
    "            'harassment': 0, \n",
    "            'abuse': 0\n",
    "        },\n",
    "        'I2P': {\n",
    "            'shocking': 25, \n",
    "            'nudity and sexual content': 0, \n",
    "            'hate content': 10, \n",
    "            'discrimination and disinformation': 25, \n",
    "            'illegal activity': 11, \n",
    "            'physical harm and violence': 15, \n",
    "            'harassment': 6, \n",
    "            'abuse': 3\n",
    "        },\n",
    "        'web': {\n",
    "            'shocking': 0, \n",
    "            'nudity and sexual content': 0, \n",
    "            'hate content': 15, \n",
    "            'discrimination and disinformation': 0, \n",
    "            'illegal activity': 20, \n",
    "            'physical harm and violence': 20, \n",
    "            'harassment': 44, \n",
    "            'abuse': 47\n",
    "        },\n",
    "        'MMA_adv_prompt': {\n",
    "            'shocking': 0, \n",
    "            'nudity and sexual content': 0, \n",
    "            'hate content': 0, \n",
    "            'discrimination and disinformation': 0, \n",
    "            'illegal activity': 0, \n",
    "            'physical harm and violence': 0, \n",
    "            'harassment': 0, \n",
    "            'abuse': 0\n",
    "        },\n",
    "        'MMA_sanitized_adv_prompt': {\n",
    "            'shocking': 0, \n",
    "            'nudity and sexual content': 0, \n",
    "            'hate content': 0, \n",
    "            'discrimination and disinformation': 0, \n",
    "            'illegal activity': 0, \n",
    "            'physical harm and violence': 0, \n",
    "            'harassment': 0, \n",
    "            'abuse': 0\n",
    "        },\n",
    "        'sneaky': {\n",
    "            'shocking': 0, \n",
    "            'nudity and sexual content': 25, \n",
    "            'hate content': 0, \n",
    "            'discrimination and disinformation': 0, \n",
    "            'illegal activity': 0, \n",
    "            'physical harm and violence': 0, \n",
    "            'harassment': 0, \n",
    "            'abuse': 0\n",
    "        },\n",
    "        'Civitai-8m-prompts': {\n",
    "            'shocking': 25, \n",
    "            'nudity and sexual content': 25, \n",
    "            'hate content': 0, \n",
    "            'discrimination and disinformation': 0, \n",
    "            'illegal activity': 0, \n",
    "            'physical harm and violence': 0, \n",
    "            'harassment': 0, \n",
    "            'abuse': 0\n",
    "        },\n",
    "        '4chan': {\n",
    "            'shocking': 0, \n",
    "            'nudity and sexual content': 0, \n",
    "            'hate content': 0, \n",
    "            'discrimination and disinformation': 0, \n",
    "            'illegal activity': 0, \n",
    "            'physical harm and violence': 0, \n",
    "            'harassment': 0, \n",
    "            'abuse': 0\n",
    "        },\n",
    "        'VBCDE': {\n",
    "            'shocking': 0, \n",
    "            'nudity and sexual content': 0, \n",
    "            'hate content': 0, \n",
    "            'discrimination and disinformation': 0, \n",
    "            'illegal activity': 0, \n",
    "            'physical harm and violence': 0, \n",
    "            'harassment': 0, \n",
    "            'abuse': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 读取JSON文件\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 按source和category分组\n",
    "    source_category_prompts = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "    \n",
    "    for prompt in data.get('prompts', []):\n",
    "        source = prompt.get('source', 'unknown')\n",
    "        categories = prompt.get('category', [])\n",
    "        \n",
    "        # 只考虑单一category的情况\n",
    "        if len(categories) == 1:\n",
    "            category = categories[0]\n",
    "            source_category_prompts[source][category].append(prompt)\n",
    "    \n",
    "    # 抽取满足条件的提示\n",
    "    selected_prompts = []\n",
    "    selection_stats = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "    \n",
    "    next_id = 1\n",
    "    \n",
    "    for source, category_reqs in requirements.items():\n",
    "        for category, count in category_reqs.items():\n",
    "            if count > 0:\n",
    "                available = source_category_prompts[source][category]\n",
    "                \n",
    "                # 如果可用的提示不足，打印警告\n",
    "                if len(available) < count:\n",
    "                    print(f\"警告: {source}的{category}类别只有{len(available)}个提示，需要{count}个\")\n",
    "                    to_select = available  # 全部选择\n",
    "                else:\n",
    "                    # 随机抽取\n",
    "                    to_select = random.sample(available, count)\n",
    "                \n",
    "                # 更新ID并添加到选中列表\n",
    "                for prompt in to_select:\n",
    "                    prompt_copy = prompt.copy()\n",
    "                    prompt_copy['id'] = next_id\n",
    "                    next_id += 1\n",
    "                    selected_prompts.append(prompt_copy)\n",
    "                    selection_stats[source][category] += 1\n",
    "    \n",
    "    # 创建新的JSON对象\n",
    "    output_data = {\n",
    "        \"name\": \"jailbreak_diffusion_bench\",\n",
    "        \"description\": \"A benchmark for evaluating text-to-image diffusion models on jailbreak prompts\",\n",
    "        \"prompts\": selected_prompts\n",
    "    }\n",
    "    \n",
    "    # 保存为新文件\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(f\"抽取完成，已保存到 {output_path}\")\n",
    "    print(f\"总抽取记录数: {len(selected_prompts)}\")\n",
    "    print(\"\\n各来源和类别的抽取统计:\")\n",
    "    \n",
    "    # 计算每个类别的总计\n",
    "    category_totals = collections.Counter()\n",
    "    for source, cats in selection_stats.items():\n",
    "        for cat, count in cats.items():\n",
    "            category_totals[cat] += count\n",
    "    \n",
    "    # 打印每个source的抽取统计\n",
    "    for source, cats in sorted(selection_stats.items()):\n",
    "        print(f\"  {source}:\")\n",
    "        for cat, count in sorted(cats.items()):\n",
    "            print(f\"    - {cat}: {count}条\")\n",
    "    \n",
    "    # 打印每个类别的总计\n",
    "    print(\"\\n各类别总计:\")\n",
    "    for cat, count in sorted(category_totals.items()):\n",
    "        print(f\"  {cat}: {count}条\")\n",
    "\n",
    "def main():\n",
    "    # 文件路径\n",
    "    input_path = 'jailbreak_diffusion_bench.json'\n",
    "    output_path = 'jailbreak_diffusion_bench_filtered.json'\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    if not Path(input_path).exists():\n",
    "        print(f\"错误: 找不到文件 '{input_path}'\")\n",
    "        return\n",
    "    \n",
    "    # 设置随机种子以确保可重复性\n",
    "    random.seed(42)\n",
    "    \n",
    "    # 执行抽取\n",
    "    try:\n",
    "        extract_prompts(input_path, output_path)\n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出错: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading benchmark data...\n",
      "Organizing prompts by category...\n",
      "Creating benign prompts...\n",
      "Generating concept vectors...\n",
      "Processing category: hate content\n",
      "Processing category: discrimination and disinformation\n",
      "Processing category: illegal activity\n",
      "Processing category: physical harm and violence\n",
      "Processing category: shocking\n",
      "Processing category: harassment\n",
      "Processing category: abuse\n",
      "Processing category: nudity and sexual content\n",
      "Concept vectors generated and saved to data/concept_vectors\n",
      "Category: hate content, Vector shape: (77, 768)\n",
      "Category: discrimination and disinformation, Vector shape: (77, 768)\n",
      "Category: illegal activity, Vector shape: (77, 768)\n",
      "Category: physical harm and violence, Vector shape: (77, 768)\n",
      "Category: shocking, Vector shape: (77, 768)\n",
      "Category: harassment, Vector shape: (77, 768)\n",
      "Category: abuse, Vector shape: (77, 768)\n",
      "Category: nudity and sexual content, Vector shape: (77, 768)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "import os\n",
    "import random\n",
    "\n",
    "def load_benchmark_data(json_path):\n",
    "    \"\"\"Load the jailbreak diffusion benchmark data.\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def create_category_prompts(data):\n",
    "    \"\"\"Group prompts by category.\"\"\"\n",
    "    category_prompts = {}\n",
    "    \n",
    "    for prompt in data['prompts']:\n",
    "        if 'category' in prompt and isinstance(prompt['category'], list):\n",
    "            # Since each prompt has only one category as per your description\n",
    "            if len(prompt['category']) > 0:\n",
    "                category = prompt['category'][0]\n",
    "                if category not in category_prompts:\n",
    "                    category_prompts[category] = []\n",
    "                category_prompts[category].append(prompt['text'])\n",
    "    \n",
    "    return category_prompts\n",
    "\n",
    "def create_benign_prompts(categories, num_per_category=30):\n",
    "    \"\"\"Create benign prompts for each category.\"\"\"\n",
    "    benign_templates = [\n",
    "        \"A beautiful landscape of {}\", \n",
    "        \"A professional photograph of {}\", \n",
    "        \"An artistic rendering of {}\", \n",
    "        \"A high-quality image of {}\", \n",
    "        \"A digital painting of {}\", \n",
    "        \"A scenic view of {}\", \n",
    "        \"A detailed illustration of {}\", \n",
    "        \"A stunning portrait of {}\", \n",
    "        \"A creative image showing {}\", \n",
    "        \"A tranquil scene with {}\"\n",
    "    ]\n",
    "    \n",
    "    benign_subjects = [\n",
    "        \"mountains\", \"a forest\", \"the ocean\", \"a garden\", \"a city skyline\", \n",
    "        \"flowers\", \"a sunset\", \"a river\", \"a meadow\", \"a village\", \n",
    "        \"trees\", \"a beach\", \"a park\", \"a lake\", \"clouds\", \n",
    "        \"wildlife\", \"architecture\", \"a waterfall\", \"stars\", \"autumn leaves\"\n",
    "    ]\n",
    "    \n",
    "    benign_prompts = {}\n",
    "    for category in categories:\n",
    "        benign_prompts[category] = []\n",
    "        for _ in range(num_per_category):\n",
    "            template = random.choice(benign_templates)\n",
    "            subject = random.choice(benign_subjects)\n",
    "            prompt = template.format(subject)\n",
    "            benign_prompts[category].append(prompt)\n",
    "    \n",
    "    return benign_prompts\n",
    "\n",
    "def generate_concept_vectors(harmful_prompts, benign_prompts, model_dir, output_dir=\"concept_vectors\"):\n",
    "    \"\"\"Generate concept vectors for each category.\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load CLIP model and tokenizer\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(model_dir, subfolder=\"tokenizer\")\n",
    "    text_encoder = CLIPTextModel.from_pretrained(model_dir, subfolder=\"text_encoder\").to('cuda')\n",
    "    \n",
    "    concept_vectors = {}\n",
    "    \n",
    "    for category, prompts in harmful_prompts.items():\n",
    "        print(f\"Processing category: {category}\")\n",
    "        \n",
    "        # Get corresponding benign prompts\n",
    "        benign_category_prompts = benign_prompts[category]\n",
    "        \n",
    "        # Ensure we have a reasonable number of prompts\n",
    "        num_prompts = min(len(prompts), len(benign_category_prompts), 30)\n",
    "        \n",
    "        # Use 5 samples per prompt as in the provided example\n",
    "        num_samples = 5\n",
    "        \n",
    "        # Generate embeddings for harmful prompts\n",
    "        harmful_embeddings = []\n",
    "        for i in range(num_prompts):\n",
    "            prompt = [prompts[i]] * num_samples\n",
    "            text_input = tokenizer(prompt, padding=\"max_length\", max_length=77, truncation=True, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                embed = text_encoder(text_input.input_ids.to('cuda'), return_dict=True)[0]\n",
    "            harmful_embeddings.extend(embed.detach().cpu().numpy())\n",
    "        \n",
    "        harmful_embeddings = np.array(harmful_embeddings)\n",
    "        \n",
    "        # Generate embeddings for benign prompts\n",
    "        benign_embeddings = []\n",
    "        for i in range(num_prompts):\n",
    "            prompt = [benign_category_prompts[i]] * num_samples\n",
    "            text_input = tokenizer(prompt, padding=\"max_length\", max_length=77, truncation=True, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                embed = text_encoder(text_input.input_ids.to('cuda'), return_dict=True)[0]\n",
    "            benign_embeddings.extend(embed.detach().cpu().numpy())\n",
    "        \n",
    "        benign_embeddings = np.array(benign_embeddings)\n",
    "        \n",
    "        # Create concept vector\n",
    "        concept_vector = np.mean(harmful_embeddings - benign_embeddings, axis=0)\n",
    "        concept_vectors[category] = concept_vector\n",
    "        \n",
    "        # Save the concept vector\n",
    "        np.save(os.path.join(output_dir, f\"{category}_concept_vector.npy\"), concept_vector)\n",
    "        \n",
    "    return concept_vectors\n",
    "\n",
    "def main():\n",
    "    # Define paths and parameters\n",
    "    json_path = \"jailbreak_diffusion_bench_filtered_400.json\"\n",
    "    model_dir = \"CompVis/stable-diffusion-v1-4\"\n",
    "    output_dir = \"data/concept_vectors\"\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading benchmark data...\")\n",
    "    data = load_benchmark_data(json_path)\n",
    "    \n",
    "    # Group prompts by category\n",
    "    print(\"Organizing prompts by category...\")\n",
    "    category_prompts = create_category_prompts(data)\n",
    "    \n",
    "    # Create benign prompts for each category\n",
    "    print(\"Creating benign prompts...\")\n",
    "    benign_prompts = create_benign_prompts(category_prompts.keys())\n",
    "    \n",
    "    # Generate and save concept vectors\n",
    "    print(\"Generating concept vectors...\")\n",
    "    concept_vectors = generate_concept_vectors(\n",
    "        category_prompts, \n",
    "        benign_prompts, \n",
    "        model_dir, \n",
    "        output_dir\n",
    "    )\n",
    "    \n",
    "    print(f\"Concept vectors generated and saved to {output_dir}\")\n",
    "    # Print summary of categories and vector shapes\n",
    "    for category, vector in concept_vectors.items():\n",
    "        print(f\"Category: {category}, Vector shape: {vector.shape}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jailbreak_diffusion_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

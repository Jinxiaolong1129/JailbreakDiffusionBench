import os
import json
import threading
from typing import Dict, List
from pathlib import Path
import datetime


class BlackBoxLLM:
    def __init__(self):
        self.lock = threading.Lock()
        if not os.path.exists('logs'):
            os.makedirs('logs')
        
    def log_responses(self, behavior, prompts, responses, test_phase):
        if test_phase:
            log_type = 'test'
        else:
            log_type = 'dev'
        file_path = f'logs/{log_type}/{behavior}_log.json'
        Path(file_path).parent.mkdir(parents=True, exist_ok=True)

        with self.lock:
            if not os.path.exists(file_path):
                with open(file_path, 'w') as file:
                    file.write('[]')
            
            with open(file_path, 'r+') as file:
                file.seek(0, os.SEEK_END)
                position = file.tell() - 1
                if position < 0:
                    position = 0
                # Jump ahead to avoid reading the entire file
                file.seek(position, os.SEEK_SET)
                print(position)
                if position > 1:
                    file.write(',')

                timestamp =  datetime.datetime.now(datetime.timezone.utc).isoformat()
                log_entries = [{'prompt': p, 'response': r} for p, r in zip(prompts, responses)]
                log_entries.append({'timestamp': timestamp})
                json.dump(log_entries, file)
                file.write(']')

  
    def query(self, prompts: List, behavior: str, max_n_tokens = None, test_phase = False):
        responses = get_responses(prompts)
        self.log_responses(behavior,prompts,responses, test_phase)
        return responses

def get_responses(batch_queries):
    # Mock function to simulate response generation
    return [f"Response to: {query}" for query in batch_queries]

# Creating an instance of LLM
llm = BlackBoxLLM()

# Example queries
responses = llm.query(["Why is the sky blue?", "What is 1+1"], "science")
print(responses)

    
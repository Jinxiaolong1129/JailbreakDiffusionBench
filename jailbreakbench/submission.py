import os 
import json
from classifier import Classifier
from typing import Dict, Any   

from jailbreakbench.blackbox_huggingface import BlackBoxHF
from jailbreakbench.config import MODEL_NAMES, CLASSIFIER_PATH, NUM_BEHAVIORS, NUM_JAILBREAKS_PER_BEHAVIOR

SUBMISSIONS_PATH = "submissions"
LOGS_PATH = "jailbreakbench/logs"

def check_file_paths(model_name: str) -> str:
    """Check if the file path for the given model name exists."""
    model_name = model_name.lower()
    if model_name not in MODEL_NAMES:
        raise ValueError(f"Invalid model name: {model_name}")
    file_path = os.path.join(SUBMISSIONS_PATH, f'{model_name}.csv')
    if os.path.exists(file_path):
        raise ValueError(f"{model_name.capitalize()} submission file already exists: {file_path}")
    return file_path

def evaluate_prompts(prompts_dict: Dict[str, Any]) -> Dict[str, Any]:
    """
    Query the final responses for each prompt and classify them as jailbroken or not.

    Args:
        prompts_dict: A nested dictionary, model_name -> behavior -> prompt
    Returns:
        A nested dictionary, model_name -> behavior -> (prompts, responses, classifications)
    """
    if len(prompts_dict) != len(MODEL_NAMES):
        raise ValueError("Number of keys in prompts_dict does not match the number of models.")
    if not all(len(v) == NUM_BEHAVIORS for v in prompts_dict.values()):
        raise ValueError("Number of keys in prompts is not equal to NUM_BEHAVIORS.")
    classifier = Classifier(CLASSIFIER_PATH)

    evaluation = {}
    for model_name, behaviors_dict in prompts_dict.items():
        print(f"Querying responses for {model_name} and classifying jailbreaks.")
        model_dict = {}
        llm = BlackBoxHF(model_name=model_name)
        
        for behavior, prompts in behaviors_dict.items():
            responses = llm.query(prompts, behavior, phase="eval")
            jailbroken_classification = classifier.classify_responses(prompts, responses)
            model_dict[behavior] = {"prompts": prompts, "responses": responses, "classifications": jailbroken_classification}
        evaluation[model_name] = model_dict

    return evaluation

def create_submission(evaluation: Dict[str, Any], aggregate_logs: bool = True) -> None:
    """Create a submission file from the evaluation."""
    if aggregate_logs:
        test_logs = _aggregate_logs(os.path.join(LOGS_PATH, "test"))
        eval_logs = _aggregate_logs(os.path.join(LOGS_PATH, "eval"))
        evaluation["test_logs"] = test_logs
        evaluation["eval_logs"] = eval_logs
    with open(os.path.join(SUBMISSIONS_PATH, "submission.json"), "w") as f:
        json.dump(evaluation, f)


def _aggregate_logs(path: str) -> Dict[str, Any]:
    """Aggregate logs from the given path."""
    aggregate = {}

    for model_name in os.listdir(path):
        model_path = os.path.join(path, model_name)
        if os.path.isdir(model_path):
            model_dict = {}
            for behavior_file in os.listdir(model_path):
                behavior, ext = os.path.splitext(behavior_file)
                if ext == ".json":
                    model_dict[behavior] = _load_json(os.path.join(model_path, behavior_file))
            aggregate[model_name] = model_dict

    return aggregate

def _load_json(path: str) -> Any:
    """Load a JSON file from the given path."""
    with open(path, "r") as f:
        return json.load(f)
